# Challenge 1 
# 03-lasso.Rmd 

Fill in the blanks to complete the below lasso code that predicts "G3" variable from the Student Performance dataset. What predictors are most strongly associated with values for "Petal.Width"? 

> HINT: Use the `03-lasso.Rmd` and `Challenge 1 - solution.Rmd` files as your guide!

### 1. Setup
- Load the Student Performance dataset 
- Load the glmnet library
- Set your seed to 1 for reproducibility

```{r}
library(rio) # painless data import and export
library(tidyverse) # tidyverse packages 
library(tidymodels) # tidymodels framework 
library(here) # reproducible way to find files 

data <-import(here("data-raw", "student-mat.csv"))
library(glmnet)
set.seed(1)
```

### 2. Define y variable as G3
```{r}
student_y = data$G3
```

### 3. Define x variables
Remove G3 from the dataset
```{r}
data_x = subset(data, data = -G3)
dim(data_x)
```

### 4. Create a features matrix
```{r}
?model.matrix
features_students = data.frame(model.matrix( ~ . -1 , data_x))
head(features_students)
```

### 5. Perform a 70/30 random split.
```{r}
(training_size = floor(0.70 * nrow(features_students)))
# Set seed for reproducibility.
set.seed(1)
training_rows_students = sample(nrow(features_students), size = training_size)
```

### 6. Partition training and test sets
```{r}
train_x_students = features_students[training_rows_students, ] # partition training dataset
test_x_students = features_students[-training_rows_students, ] # partition test dataset

train_y_students = student_y[training_rows_students] # partition training Y vector labels
test_y_students = student_y[-training_rows_students] # partition test Y vector labels

### Check lengths of x and y data
dim(train_x_students)
length(train_y_students)

dim(test_x_students)
length(test_y_students)
```

### 7. Fit lasso model and visualize lambda distribution and different lambda values
```{r}
lasso_student = cv.glmnet(as.matrix(train_x_students), train_y_students, family = "gaussian", alpha = 1)
plot(lasso_student)
plot(lasso_student$glmnet.fit, xvar = "lambda", label = T)

# View minimum MSE and higher lambda within one standard error
lasso_student$lambda.min
lasso_student$lambda.1se

# View coefficients
coef(lasso_student, s = "lambda.min")
coef(lasso_student, s = "lambda.1se")

# Predict on test set
predictions_students = predict(lasso_student, s = lasso_student$lambda.1se, newx = as.matrix(test_x_students))
```

# 8. Calculate MSE and RMSE
```{r}
# Calculate mean-squared error = 0.01883421
mean((predictions_students - test_y_students)^2)

# Calculate root mean-squared error = 0.1372378
sqrt(mean((predictions_students - test_y_students)^2))
```
