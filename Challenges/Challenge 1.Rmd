# Challenge 1 
# 03-lasso.Rmd 

Fill in the blanks to complete the below lasso code that predicts "G3" variable from the Student Performance dataset. What predictors are most strongly associated with values for "G3"? 

> HINT: Use the `03-lasso.Rmd` and `Challenge 1 - solution.Rmd` files as your guide!

### 1. Setup
- Load the student-mat.csv dataset 
- Load the glmnet library
- Set your seed to 1 for reproducibility

```{r}
library(rio) # painless data import and export
library(tidyverse) # tidyverse packages 
library(tidymodels) # tidymodels framework 
library(here) # reproducible way to find files 

data <-import(here("data-raw", "student-mat.csv"))
library(______)
___.____(1)
```

### 2. Define y variable as G3
```{r}
student_y = data$__
```

### 3. Define x variables
Remove Petal.Width from the dataset
```{r}
data_x = subset(data, ____ = -__)
dim(data_x)
```

### 4. Create a features matrix
```{r}
?model.matrix
features_students = data.frame(model.matrix( ~ . -1 , ______))
head(features_students)
```

### 5. Perform a 70/30 random split.
```{r}
(training_size = floor(0.70 * nrow(_________________)))
# Set seed for reproducibility.
set.seed(1)
training_rows_students = sample(nrow(_________________), size = _____________)
```

### 6. Partition training and test sets
```{r}
train_x_students = features_students[______________________, ] # partition training dataset
test_x_students = features_students[-______________________, ] # partition test dataset

train_y_students = student_y[______________________] # partition training Y vector labels
test_y_students = student_y[-______________________] # partition test Y vector labels

### Check lengths of x and y data
dim(train_x_students)
length(train_y_students)

dim(test_x_students)
length(test_y_students)
```

### 7. Fit lasso model and visualize lambda distribution and different lambda values
```{r}
lasso_student = cv.glmnet(as.matrix(________________), train___students, family = "gaussian", alpha = 1)
plot(lasso_student)
plot(lasso_student$glmnet.___, xvar = "lambda", label = T)

# View minimum MSE and higher lambda within one standard error
lasso_student$lambda.___
lasso_student$lambda.___

# View coefficients
coef(lasso_student, s = "lambda.___")
coef(lasso_student, s = "lambda.___")

# Predict on test set
predictions_students = predict(lasso_student, s = lasso_student$lambda.___, newx = as.matrix(_______________))
```

# 8. Calculate MSE and RMSE
```{r}
# Calculate mean-squared error = 0.0262426
mean((predictions_students - test_y_students)^2)

# Calculate root mean-squared error = 0.1619957
sqrt(mean((predictions_students - test_y_students)^2))
```
