---
title: "Solutions for Machine Learning with tidymodels"
theme: readable
output:
  html_document:
    toc: true
    toc_float: true
    fig_width: 12
    fig_height: 7
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
suppressMessages(suppressWarnings({ 
  library(tidymodels)
  library(here)
  library(palmerpenguins)
  library(tidyverse)
}))
# prefer tidymodels functions in any case of name conflict
tidymodels::tidymodels_prefer() 
```


## Challenge 1

The function we seek to learn often has more than one variable. Write the equivalent mathematical function to illustrate the relationship between flipper length, bill depth, body mass, and island. Choose any feature and graph the relationship with a machine learning smoother. 

```{r}


```

## Challenge 2

Think about your own interests. Come up and write down an example problem that is either a supervised or unsupervised learning problem. What kind of data would you want to have on hand to be able to estimate the relationship of interest? 

*Answers will obviously vary. The key point is that supervised learning problems should be able to describe the dataset in terms of labels.*

## Challenge 3 

Explain whether the following are classification or regression problems 

1. An advertiser is interested in the relationship between age and amount of hours of YouTube consumed. *regression. hours is quantitative*

2. A medical testing company conducts a procedure to determine whether a person has a cancer diagnosis. *classification. a person has cancer or they do not*

3. A researcher is interested in the effect of an education intervention on students' test scores. *regression. test scores is quantitative. However, we can imagine this problem being categorical if the test scores were not ordered. For example, someone's "learning style"*

## Challenge 4 

Sometimes features on different scales can lead to strange predictions and poor test fit. Therefore, one step that analysts may take is to center and normalize their data. Using the reference link, identify the function that normalizes data and add it to the recipe to apply it all numeric predictors in the data. 

```{r}
challenge4_recipe <- recipe(bill_length_mm ~ ., data = penguins_train)%>%
  step_normalize(all_numeric_predictors())
```


## Challenge 5 

Write and fit a logistic regression specification to classify penguin sex based on all other features. You will have to make three changes from the linear specification. Use `glm` as your engine. 

```{r}
class_model <- logistic_reg()%>%
  set_engine("glm")%>%
  set_mode("classification")%>%
  fit(sex ~ ., data = penguins_train)
```

## Challenge 6 

Write a new recipe that predicts bill length from bill depth, flipper length, and body mass only. Normalize all variables. Write a workflow that uses your new recipe to fit a linear model. 


```{r}
challenge6_recipe <- recipe(bill_depth_mm ~ bill_depth_mm + flipper_length_mm + body_mass_g, data = penguins_train)%>%
  step_normalize(all_numeric_predictors())

# we could just use the lm_model specification we already have
# for completeness included here as well 
lm_model <- linear_reg()%>%
  set_engine("lm")%>%
  set_mode("regression")

challenge6_wflow <- workflow()%>%
  add_recipe(challenge6_recipe)%>%
  add_model(lm_model)

challenge6_fit <- fit(challenge6_wflow, penguins_train)
challenge6_fit %>% 
  tidy()

## We could also predict new points 
## Again just slicing the first five values for teaching purposes 
## For a real model you would use the full test set
predict(challenge6_fit, new_data = penguins_test %>% slice(1:5))
```

## Challenge 7 

Using the `challenge7` dataset, evaluate the relationship between *Y* and the remaining set of features with all three kinds of linear regression models we have seen so far. Which model performs the best on the test set? 


### Challenge 7 

Using the `challenge7` dataset, predict whether a penguin is a Gentoo using the remaining set of features with all three kinds of linear regression models we have seen so far. Which model performs the best on the test set? 


```{r}
# seed for this challenge 
set.seed(3811212514757)

challenge7 <- penguins %>% 
  mutate(isChinstrap = if_else(species == "Gentoo", TRUE, FALSE))

## Data spend 
## Set up train and test set 
c7_split <- initial_split(challenge7, prop = .75)

c7_train <- training(c7_split)
c7_test <- testing(c7_split)

## specify cross validation split with 10 folds 
c7_kfolds <- vfold_cv(c7_train, v = 10)
```

### Challenge 8: Putting everything together 

Using the same dataset as Challenge 7, fit at least three different models working through the process we have covered in this workshop. The goal for this problem is to correctly classify penguins into "Gentoo" or "Not Gentoo" types. 

```{r}
set.seed(1234)

## Read in data 

## Data spend 

## Create Model specifications 

## Create Recipes 

## Fit and tune model specifications 

## Choose the best one 

## Evaluate the model

```